set.seed(1)
x = rnorm(100)
y<- x-2*x^2+rnorm(100)
xyValues <- data.frame(x, y)
glmfit_linear = glm(y~x)
cv.glm(xyValues,glmfit_linear)
cv.glm(xyValues,glmfit_linear)$delta[1]
summary((glmfit_linear))
glmfit_2 <- glm(y ~ poly(x, 2))
cv.glm(xyValues,glmfit_2)$delta[1]
glmfit_3 <- glm(y ~ poly(x, 3))
cv.glm(xyValues,glmfit_3)$delta[1]
plot(x,y , main='Plot of X and Y',xlab ='X coordinate values', ylab = 'Y coordinate values')
glmfit_4 <- glm(y ~ poly(x, 4))
cv.glm(xyValues,glmfit_4)$delta[1]
cv.glm(xyValues,glmfit_3)
glmfit_1
rm(list=ls())
library(caret)
library(boot)
set.seed(1)
x = rnorm(100)
y<- x-2*x^2+rnorm(100)
plot(x,y , main='Plot of X vs Y',xlab ='X coordinate values', ylab = 'Y coordinate values')
xyValues <- data.frame(x, y)
glmfit_1 = glm(y~x)
summary((glmfit_1))
cv.glm(xyValues,glmfit_1)$delta[1]
glmfit_1
glmfit_1$coefficients
coeff1 <- glmfit_1$coefficients
coeff2 <- glmfit_2$coefficients
rm(list=ls())
library(caret)
library(boot)
set.seed(1)
x = rnorm(100)
y<- x-2*x^2+rnorm(100)
plot(x,y , main='Plot of X vs Y',xlab ='X coordinate values', ylab = 'Y coordinate values')
xyValues <- data.frame(x, y)
glmfit_1 = glm(y~x)
summary((glmfit_1))
cv.glm(xyValues,glmfit_1)$delta[1]
coeff1 <- glmfit_1$coefficients
glmfit_2 <- glm(y ~ poly(x, 2))
cv.glm(xyValues,glmfit_2)$delta[1]
coeff2 <- glmfit_2$coefficients
glmfit_3 <- glm(y ~ poly(x, 3))
cv.glm(xyValues,glmfit_3)$delta[1]
coeff3 <- glmfit_3$coefficients
glmfit_4 <- glm(y ~ poly(x, 4))
cv.glm(xyValues,glmfit_4)$delta[1]
coeff4 <- glmfit_4$coefficients
cv.glm(xyValues,glmfit_3)
cv.glm(xyValues,glmfit_1)$delta[0]
cv.glm(xyValues,glmfit_1)$delta[3]
cv.glm(xyValues,glmfit_1)$delta[1]
cv.glm(xyValues,glmfit_1)$delta[2]
cv.glm(xyValues,glmfit_1)$delta[1]
rm(list=ls())
rm(list=ls())
library(ISLR)
library(MASS)
install.packages("caret")
install.packages("e1071")
library(caret)
library(e1071)
BostonData <- Boston;
names(BostonData)
medCrime <- median(BostonData$crim)
#0.25651 - median value of crim
#modified the Boston Data to set values above median to 1 and below Median to 0
BostonData$crim[BostonData$crim<medCrime] <- 0
BostonData$crim[BostonData$crim>medCrime] <- 1
#########################################
# Creating a training and test set
#########################################
set.seed(1)
train <- sample(1:nrow(BostonData), .70*nrow(BostonData))
b_train <- BostonData[train,]
b_test <- BostonData[-train,]
crim_train <- as.numeric(b_train$crim)  #original crim training data
crim_test <- as.numeric(b_test$crim)  #original crim test data
#########################################
# Logistic Regression
#########################################
lr.fit <- glm(crim ~., data = b_train, family = "binomial")
summary(lr.fit)
names(lr.fit)
# Predicting the values
lr_pred_crim_train <- predict(lr.fit, newdata = b_train[,-1], type = "response")
lr_pred_crim_train <- round(lr_pred_crim_train)
lr_pred_crim_test <- predict(lr.fit, newdata = b_test[,-1], type = "response")
lr_pred_crim_test <- round(lr_pred_crim_test)
#  Calculate the mean sq error rates
lr_train_err <- sum((crim_train - lr_pred_crim_train)^2)/length(crim_train)
lr_test_err <- sum((crim_test - lr_pred_crim_test)^2)/length(crim_test)
lr_train_err #0.09039548
lr_test_err #0.07894737
lr_conf <- confusionMatrix(lr_pred_crim_test, crim_test)
names(lr_conf)
lr_conf$table
#########################################
# LDA
#########################################
lda.fit <- lda(crim~., data = b_train)
lda_pred_crim_train <- predict(lda.fit, newdata = b_train[,-1])
lda_pred_crim_train <- as.numeric(lda_pred_crim_train$class)-1
lda_pred_crim_test <- predict(lda.fit, newdata = b_test[,-1])
lda_pred_crim_test <- as.numeric(lda_pred_crim_test$class)-1
#  Calculate the mean sq error rates
lda_train_err <- sum((crim_train - lda_pred_crim_train)^2)/length(crim_train)
lda_test_err <- sum((crim_test - lda_pred_crim_test)^2)/length(crim_test)
lda_train_err #0.1242938
lda_test_err #0.1315789
lda_conf <- confusionMatrix(lda_pred_crim_test, crim_test)
names(lda_conf)
lda_conf$table
#########################################
# KNN
#########################################
require(class)
knn1_pred_crim_train <- as.numeric(knn(b_train[,-1], b_train[,-1], b_train[,1], 1))-1
knn1_pred_crim_test <- as.numeric(knn(b_train[,-1], b_test[,-1], b_train[,1], 1))-1
#  Calculate the mean sq error rates
knn_train_err <- sum((crim_train - knn1_pred_crim_train)^2)/length(crim_train)
knn_test_err <- sum((crim_test - knn1_pred_crim_test)^2)/length(crim_test)
knn_train_err #0
knn_test_err #0.07894737
install.packages("caret")
library(MASS)
rm(list=ls())
library(ISLR)
library(MASS)
#install.packages("caret")
#install.packages("e1071")
library(caret)
library(e1071)
BostonData <- Boston;
names(BostonData)
medCrime <- median(BostonData$crim)
#0.25651 - median value of crim
#modified the Boston Data to set values above median to 1 and below Median to 0
BostonData$crim[BostonData$crim<medCrime] <- 0
BostonData$crim[BostonData$crim>medCrime] <- 1
#########################################
# Creating a training and test set
#########################################
set.seed(1)
train <- sample(1:nrow(BostonData), .70*nrow(BostonData))
b_train <- BostonData[train,]
b_test <- BostonData[-train,]
crim_train <- as.numeric(b_train$crim)  #original crim training data
crim_test <- as.numeric(b_test$crim)  #original crim test data
#########################################
# Logistic Regression
#########################################
lr.fit <- glm(crim ~., data = b_train, family = "binomial")
summary(lr.fit)
names(lr.fit)
# Predicting the values
lr_pred_crim_train <- predict(lr.fit, newdata = b_train[,-1], type = "response")
lr_pred_crim_train <- round(lr_pred_crim_train)
lr_pred_crim_test <- predict(lr.fit, newdata = b_test[,-1], type = "response")
lr_pred_crim_test <- round(lr_pred_crim_test)
#  Calculate the mean sq error rates
lr_train_err <- sum((crim_train - lr_pred_crim_train)^2)/length(crim_train)
lr_test_err <- sum((crim_test - lr_pred_crim_test)^2)/length(crim_test)
lr_train_err #0.09039548
lr_test_err #0.07894737
lr_conf <- confusionMatrix(lr_pred_crim_test, crim_test)
names(lr_conf)
lr_conf$table
#########################################
# LDA
#########################################
lda.fit <- lda(crim~., data = b_train)
lda_pred_crim_train <- predict(lda.fit, newdata = b_train[,-1])
lda_pred_crim_train <- as.numeric(lda_pred_crim_train$class)-1
lda_pred_crim_test <- predict(lda.fit, newdata = b_test[,-1])
lda_pred_crim_test <- as.numeric(lda_pred_crim_test$class)-1
#  Calculate the mean sq error rates
lda_train_err <- sum((crim_train - lda_pred_crim_train)^2)/length(crim_train)
lda_test_err <- sum((crim_test - lda_pred_crim_test)^2)/length(crim_test)
lda_train_err #0.1242938
lda_test_err #0.1315789
lda_conf <- confusionMatrix(lda_pred_crim_test, crim_test)
names(lda_conf)
lda_conf$table
#########################################
# KNN
#########################################
require(class)
knn1_pred_crim_train <- as.numeric(knn(b_train[,-1], b_train[,-1], b_train[,1], 1))-1
knn1_pred_crim_test <- as.numeric(knn(b_train[,-1], b_test[,-1], b_train[,1], 1))-1
#  Calculate the mean sq error rates
knn_train_err <- sum((crim_train - knn1_pred_crim_train)^2)/length(crim_train)
knn_test_err <- sum((crim_test - knn1_pred_crim_test)^2)/length(crim_test)
knn_train_err #0
knn_test_err #0.07894737
names(BostonData)
rm(list=ls())
library(ISLR)
library(MASS)
library(caret)
library(e1071)
BostonData <- Boston;
names(BostonData)
medCrime <- median(BostonData$crim)
medCrime
summary(lr.fit)
rm(list=ls())
library(ISLR)
library(MASS)
library(caret)
library(e1071)
BostonData <- Boston;
names(BostonData)
medCrime <- median(BostonData$crim)
medCrime
BostonData$crim[BostonData$crim<medCrime] <- 0
BostonData$crim[BostonData$crim>medCrime] <- 1
set.seed(1)
train <- sample(1:nrow(BostonData), .70*nrow(BostonData))
b_train <- BostonData[train,]
b_test <- BostonData[-train,]
crim_train <- as.numeric(b_train$crim)  #original crim training data
crim_test <- as.numeric(b_test$crim)  #original crim test data
lr.fit <- glm(crim ~., data = b_train, family = "binomial")
summary(lr.fit)
lr_pred_crim_train <- predict(lr.fit, newdata = b_train[,-1], type = "response")
names(lr.fit)
lr_pred_crim_train <- predict(lr.fit, newdata = b_train[,-1], type = "response")
lr_pred_crim_train <- round(lr_pred_crim_train)
lr_pred_crim_test <- predict(lr.fit, newdata = b_test[,-1], type = "response")
lr_pred_crim_test <- round(lr_pred_crim_test)
lr_train_err <- sum((crim_train - lr_pred_crim_train)^2)/length(crim_train)
lr_test_err <- sum((crim_test - lr_pred_crim_test)^2)/length(crim_test)
lr_train_err #0.09039548
lr_test_err #0.07894737
lr_conf <- confusionMatrix(lr_pred_crim_test, crim_test)
names(lr_conf)
lr_conf$table
lda.fit <- lda(crim~., data = b_train)
summary(lda.fit)
names(lda.fit)
lda.fit <- lda(crim~., data = b_train)
lda(crim~., data = b_train)
lda.fit <-
lda(crim~., data = b_train)
lda(crim~., data = b_train)
lda.fit <- lda(crim~., data = b_train)
lda_pred_crim_train <- predict(lda.fit, newdata = b_train[,-1])
lda_pred_crim_train <- as.numeric(lda_pred_crim_train$class)-1
lda_pred_crim_test <- predict(lda.fit, newdata = b_test[,-1])
lda_pred_crim_test <- as.numeric(lda_pred_crim_test$class)-1
lda_train_err <- sum((crim_train - lda_pred_crim_train)^2)/length(crim_train)
lda_test_err <- sum((crim_test - lda_pred_crim_test)^2)/length(crim_test)
lda_train_err #0.1242938
lda_test_err #0.1315789
lda_conf <- confusionMatrix(lda_pred_crim_test, crim_test)
names(lda_conf)
lda_conf$table
require(class)
knn1_pred_crim_train <- as.numeric(knn(b_train[,-1], b_train[,-1], b_train[,1], 1))-1
knn1_pred_crim_test <- as.numeric(knn(b_train[,-1], b_test[,-1], b_train[,1], 1))-1
knn_train_err <- sum((crim_train - knn1_pred_crim_train)^2)/length(crim_train)
knn_test_err <- sum((crim_test - knn1_pred_crim_test)^2)/length(crim_test)
knn_train_err #0
knn_test_err #0.07894737
knn_train_err #0
knn_test_err #0.07894737
knn_conf <- confusionMatrix(knn_pred_crim_test, crim_test)
knn1_pred_crim_train <- as.numeric(knn(b_train[,-1], b_train[,-1], b_train[,1], 1))-1
knn1_pred_crim_test <- as.numeric(knn(b_train[,-1], b_test[,-1], b_train[,1], 1))-1
knn_train_err <- sum((crim_train - knn1_pred_crim_train)^2)/length(crim_train)
knn_test_err <- sum((crim_test - knn1_pred_crim_test)^2)/length(crim_test)
knn_train_err #0
knn_test_err #0.07894737
knn_conf <- confusionMatrix(knn_pred_crim_test, crim_test)
knn_conf <- confusionMatrix(knn1_pred_crim_test, crim_test)
names(knn_conf)
knn_conf$table
summary(lr.fit)
rm(list = ls())
df <- read.table("https://astro.temple.edu/~alan/DiabetesAndrews36_1.txt",header = FALSE)
diabetesdf <- subset(df , select= -c(V1,V2,V3,V4))
diabetesdf <- subset(df , select= -c(V1,V2,V3,V4))
View(diabetesdf)
View(diabetesdf)
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V5 ~ V7, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V5 ~ V8, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V5 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V6 ~ V7, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V6 ~ V8, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V6 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V7 ~ V8, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V7 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V8 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"))
pairs(diabetesdf)
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V5 ~ V7, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V5 ~ V8, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V5 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V6 ~ V7, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V6 ~ V8, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V6 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V7 ~ V8, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V7 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V8 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"))
pairs(diabetesdf)
set.seed(1)
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right",points = FALSE , lines=TRUE))
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right",points = 4 , lines=TRUE))
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right",points = FALSE))
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right",points = TRUE))
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right"),type='o' , pch=10, cex=.2)
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right"),type='o' , cex=.2)
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right"),type='o' , pch=10)
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right") , pch=10)
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V5 ~ V7, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V5 ~ V8, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V5 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V6 ~ V7, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V6 ~ V8, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V6 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V7 ~ V8, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V7 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V8 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"))
pairs(diabetesdf)
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right"))
xyplot(V6 ~ V7, group=V10, data=diabetesdf,auto.key=list(space="right"),ylab = 'glucose.area',xlab = )
xyplot(V5 ~ V6, group=V10, data=diabetesdf,auto.key=list(space="right"),ylab = 'glucose.area',xlab = 'insulin.area')
xyplot(V5 ~ V7, group=V10, data=diabetesdf,auto.key=list(space="right"),ylab = 'glucose.area',xlab = 'SSPG')
xyplot(V5 ~ V8, group=V10, data=diabetesdf,auto.key=list(space="right"),ylab = 'glucose.area',xlab = 'relative.weight')
xyplot(V5 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"),ylab = 'glucose.area',xlab = 'fasting.plasma.glucose')
xyplot(V6 ~ V7, group=V10, data=diabetesdf,auto.key=list(space="right"),ylab = 'insulin.area',xlab = 'SSPG')
xyplot(V6 ~ V8, group=V10, data=diabetesdf,auto.key=list(space="right"),ylab = 'insulin.area',xlab = 'relative.weight')
xyplot(V6 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"),ylab = 'insulin.area',xlab = 'fasting.plasma.glucose')
xyplot(V7 ~ V8, group=V10, data=diabetesdf,auto.key=list(space="right"),ylab = 'SSPG',xlab = 'relative.weight')
xyplot(V7 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"),ylab = 'SSPG',xlab = 'fasting.plasma.glucose')
xyplot(V8 ~ V9, group=V10, data=diabetesdf,auto.key=list(space="right"),ylab = 'relative.weight',xlab = 'fasting.plasma.glucose')
lda.fit <- lda(V10~., data = d_train)
pairs(diabetesdf)
set.seed(1)
train <- sample(1:nrow(diabetesdf), .75*nrow(diabetesdf))
d_train <- diabetesdf[train,]
d_test <- diabetesdf[-train,]
d_true_train <- d_train[,6]
d_true_test <- d_test[,6]
lda.fit <- lda(V10~., data = d_train)
summary(lda.fit)
lda(V10~., data = d_train)
lda.pred.train <- predict(lda.fit, newdata = d_train[,-6])
lda.pred.train <- as.numeric(lda.pred.train$class)
lda.pred.test <- predict(lda.fit, newdata = d_test[,-6])
lda.pred.test <- as.numeric(lda.pred.test$class)
lda_train_error <- sum((d_true_train - lda.pred.train)^2)/length(d_true_train)
lda_test_error <- sum((d_true_test - lda.pred.test)^2)/length(d_true_test)
lda_train_error #0.1018519
lda_test_error #0.1621622
actual.data <- d_test[,6]
library(caret)
actual.data <- d_test[,6]
lda_conf <- confusionMatrix(lda.pred.test, actual_data)
actual.data <- d_test[,6]
lda_conf <- confusionMatrix(lda.pred.test, actual.data)
names(lda_conf)
lda_conf$table
qda.fit <- qda(V10~., data = d_train)
qda.pred.train <- predict(qda.fit, newdata = d_train[,-6])
qda.pred.train <- as.numeric(qda.pred.train$class)
qda.pred.test <- predict(qda.fit, newdata = d_test[,-6])
qda.pred.test <- as.numeric(qda.pred.test$class)
qda_train_error <- sum((d_true_train - qda.pred.train)^2)/length(d_true_train)
qda_test_error <- sum((d_true_test - qda.pred.test)^2)/length(d_true_test)
qda_train_error #0.02777778
qda_test_error #0.08108108
qda_conf <- confusionMatrix(qda.pred.test, d_true_test)
names(qda_conf)
qda_conf$table
lda_conf$table
lda_conf <- confusionMatrix(lda.pred.test, d_true_test)
names(lda_conf)
lda_conf$table
qda.fit <- qda(V10~., data = d_train)
qda(V10~., data = d_train)
qda.pred.train <- predict(qda.fit, newdata = d_train[,-6])
qda.pred.train <- as.numeric(qda.pred.train$class)
qda.pred.test <- predict(qda.fit, newdata = d_test[,-6])
qda.pred.test <- as.numeric(qda.pred.test$class)
qda_train_error <- sum((d_true_train - qda.pred.train)^2)/length(d_true_train)
qda_test_error <- sum((d_true_test - qda.pred.test)^2)/length(d_true_test)
qda_train_error #0.02777778
qda_test_error #0.08108108
qda_conf <- confusionMatrix(qda.pred.test, d_true_test)
names(qda_conf)
qda_conf$table
data <- as.data.frame(t(c(0.98,122,544,186,184)))
names(data) <- names(d_train[,-6])
lda.pred <- predict(lda.fit, newdata = data)
lda.pred <- as.numeric(lda.pred$class)
lda.pred #2
qda.pred <- predict(qda.fit, newdata = data)
qda.pred <- as.numeric(qda.pred$class)
qda.pred #2
rm(list=ls())
library(caret)
library(boot)
set.seed(1)
x = rnorm(100)
y<- x-2*x^2+rnorm(100)
plot(x,y , main='Plot of X vs Y',xlab ='X coordinate values', ylab = 'Y coordinate values')
glmfit_1 = glm(y~x)
summary((glmfit_1))
glmfit_1 = glm(y~x)
summary((glmfit_1))
cv.glm(xyValues,glmfit_1)$delta[1]
glmfit_1 = glm(y~x)
summary((glmfit_1))
cv.glm(xyValues,glmfit_1)$delta[1]
xyValues <- data.frame(x, y)
cv.glm(xyValues,glmfit_1)$delta[1]
coeff1 <- glmfit_1$coefficients
coeff1
glmfit_2 <- glm(y ~ poly(x, 2))
summary(glmfit_2)
cv.glm(xyValues,glmfit_2)$delta[1]
coeff2 <- glmfit_2$coefficients
coeff2
glmfit_3 <- glm(y ~ poly(x, 3))
summary(glmfit_3)
cv.glm(xyValues,glmfit_3)$delta[1]
coeff3 <- glmfit_3$coefficients
coeff3
glmfit_4 <- glm(y ~ poly(x, 4))
summary(glmfit_4)
cv.glm(xyValues,glmfit_4)$delta[1]
coeff4 <- glmfit_4$coefficients
coeff4 <- glmfit_4$coefficients
coeff4
install.packages("tm") #text mining
install.packages("SnowballC")
install.packages("wordcloud")
install.packages("RColorBrewer")
rm(list = ls())
text <- readLines(file.choose())
stext <- readLines(file.choose())
doc <- Corpus(VectorSource((stext)))
doc <- corpus(VectorSource((stext)))
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
stext <- readLines(file.choose())
doc <- Corpus(VectorSource((stext)))
inspect(docs)
inspect(doc)
rm(list = ls())
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
stext <- readLines(file.choose())
stext <- readLines(file.choose())
doc <- Corpus(VectorSource((stext)))
inspect(doc)
toSpace <- content_transformer(function (x, pattern) gsub(pattern, " ", x))
doc <- tm_map(doc, toSpace, "/")
doc <- tm_map(doc, toSpace, "@")
doc <- tm_map(doc, toSpace, "\\|")
doc <- tm_map(doc, toSpace, "-")
doc <- tm_map(doc, content_transformer(tolower))
doc <- tm_map(doc, removeNumbers)
doc <- tm_map(doc, removeWords, stopwords("english"))
doc <- tm_map(doc, removeWords, c("nada", "zilch"))
doc <- tm_map(doc, removePunctuation)
doc <- tm_map(doc, stripWhitespace)
doc<- tm_map(doc, stemDocument)
doc
tdm <- TermDocumentMatrix(doc)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
wordcloud(words = d$word, freq = d$freq , min.freq = 1, max.words = 300,
random.order = FALSE, rot.per = 0.35,colors = brewer.pal(8,"Dark2"))
wordcloud(words = d$word, freq = d$freq , min.freq = 1, max.words = 200,
random.order = FALSE, rot.per = 0.35,colors = brewer.pal(8,"Dark2"))
wordcloud(words = d$word, freq = d$freq , min.freq = 1, max.words = 200,
random.order = FALSE, rot.per = 0.15,colors = brewer.pal(8,"Dark2"))
wordcloud(words = d$word, freq = d$freq , min.freq = 1, max.words = 100,
random.order = FALSE, rot.per = 0.15,colors = brewer.pal(8,"Dark2"))
wordcloud(words = d$word, freq = d$freq , min.freq = 1, max.words = 200,
random.order = FALSE, rot.per = 0.15,colors = brewer.pal(8,"Dark2"))
findFreqTerms(tdm, lowfreq = 4)
wordcloud(words = d$word, freq = d$freq , min.freq = 1, max.words = 300,
random.order = FALSE, rot.per = 0.15,colors = brewer.pal(8,"Dark2"))
stext <- readLines(file.choose())
wordcloud(words = d$word, freq = d$freq , min.freq = 1, max.words = 200,
random.order = FALSE, rot.per = 0.15,colors = brewer.pal(8,"Dark2"))
setwd('C:\DragonBallZ\Spring2018\DIC_CSE587\Lab1')
setwd('C:/DragonBallZ/Spring2018/DIC_CSE587/Lab1')
install.packages("twitteR")
library(twitteR)
